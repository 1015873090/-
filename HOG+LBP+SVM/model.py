# from sklearnex import patch_sklearn
# patch_sklearn()

EMOTIONS = ['angry', 'disgusted', 'fearful',
            'happy', 'sad', 'surprised', 'neutral']

import cv2
import os
import joblib
import numpy as np
import pandas as pd
from skimage.feature import hog
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from joblib import Parallel, delayed
from albumentations import (
    Compose, HorizontalFlip, RandomBrightnessContrast,
    ShiftScaleRotate, ToFloat
)
from skimage.feature import local_binary_pattern
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from joblib import parallel_backend

# LBPå¤šå°ºåº¦å‚æ•°é…ç½®
LBP_SCALES = [
    {'radius': 1, 'n_points': 8},   # å°å°ºåº¦æ•æ‰ç»†èŠ‚
    {'radius': 2, 'n_points': 16},  # ä¸­å°ºåº¦
    {'radius': 3, 'n_points': 24}   # å¤§å°ºåº¦
]

# HOGå‚æ•°é…ç½®
HOG_PARAMS = {
    'orientations': 9,
    'pixels_per_cell': (8, 8),
    'cells_per_block': (2, 2),
    'block_norm': 'L2-Hys',
    'transform_sqrt': True  # ä¼½é©¬æ ¡æ­£
}

# ä¿®æ”¹æ•°æ®å¢å¼ºé…ç½®ï¼ˆé¿å…ç ´åLBPçº¹ç†ï¼‰
AUGMENTATIONS = Compose([
    HorizontalFlip(p=0.3),
    RandomBrightnessContrast(
        brightness_limit=0.1,
        contrast_limit=0.1,
        p=0.3
    )
])

def extract_lbp_features(image):
    """å¤šå°ºåº¦ LBP ç‰¹å¾æå–"""
    scales = [
        {'radius': 1, 'n_points': 8},  # å°å°ºåº¦
        {'radius': 2, 'n_points': 16},  # ä¸­å°ºåº¦
        {'radius': 3, 'n_points': 24}  # å¤§å°ºåº¦
    ]
    hist = []
    for params in scales:
        lbp = local_binary_pattern(
            image,
            P=params['n_points'],
            R=params['radius'],
            method='uniform'
        )
        scale_hist, _ = np.histogram(
            lbp.ravel(),
            bins=np.arange(0, params['n_points'] + 3),
            density=True
        )
        hist.extend(scale_hist)

    # æ·»åŠ å…¨å±€ç‰¹å¾ï¼ˆå¦‚ç°åº¦ç›´æ–¹å›¾ï¼‰
    global_hist, _ = np.histogram(image.ravel(), bins=16, density=True)
    hist.extend(global_hist)

    return np.array(hist)

def extract_hog_features(data):
    """ä»åƒç´ æ•°æ®ä¸­æå–HOGç‰¹å¾"""
    if isinstance(data, (str, bytes)):
        if isinstance(data, bytes):
            data = data.decode('utf-8', errors='ignore')
        pixel_list = list(map(int, data.split()))
        if len(pixel_list) != 48 * 48:
            raise ValueError(f"åƒç´ æ•°é‡é”™è¯¯ï¼š{len(pixel_list)}ï¼ˆåº”=2304ï¼‰")
        image = np.array(pixel_list, dtype=np.uint8).reshape(48, 48)
    elif isinstance(data, np.ndarray):
        image = data.reshape(48, 48) if data.size == 2304 else data
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹")

    try:
        augmented = image
    except Exception as e:
        print(f"âš ï¸ æ•°æ®å¢å¼ºå¤±è´¥ï¼š{str(e)}")
        augmented = image

    # æå–HOGç‰¹å¾
    features = hog(
        augmented,
        orientations=HOG_PARAMS['orientations'],
        pixels_per_cell=HOG_PARAMS['pixels_per_cell'],
        cells_per_block=HOG_PARAMS['cells_per_block'],
        block_norm=HOG_PARAMS['block_norm']
    )
    return features

def extract_hybrid_features(image):
    """æ··åˆç‰¹å¾æå–ï¼ˆHOG + LBPï¼‰"""
    hog_feat = extract_hog_features(image)
    lbp_feat = extract_lbp_features(image)
    return np.concatenate([hog_feat, lbp_feat])

def extract_features(data):
    """ç»Ÿä¸€ç‰¹å¾æå–å…¥å£"""
    if isinstance(data, (str, bytes)):
        if isinstance(data, bytes):
            data = data.decode('utf-8', errors='ignore')
        pixel_list = list(map(int, data.split()))
        image = np.array(pixel_list, dtype=np.uint8).reshape(48, 48)
    elif isinstance(data, np.ndarray):
        image = data.reshape(48, 48) if data.size == 2304 else data
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹")

    return extract_hybrid_features(image)

def load_data(data_path):
    """åŠ è½½æ•°æ®å¹¶æå–ç‰¹å¾"""
    print("â³ åŠ è½½æ•°æ®å¹¶æå–ç‰¹å¾...")
    df = pd.read_csv(data_path)

    # æ•°æ®éªŒè¯
    invalid_samples = []
    for idx, pixels in enumerate(df['pixels']):
        if len(pixels.split()) != 2304:
            invalid_samples.append(idx)

    # ç‰¹å¾æå–
    X = Parallel(n_jobs=-1, verbose=10)(
        delayed(extract_features)(pixels)
        for pixels in df['pixels']
    )

    X = np.array(X)
    y = df['emotion'].values
    print(f"\nâœ… ç‰¹å¾æå–å®Œæˆï¼Œç‰¹å¾çŸ©é˜µå½¢çŠ¶ï¼š{X.shape}")
    return X, y

def train_model(data_path, save_dir):
    try:
        X, y = load_data(data_path)
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, stratify=y, random_state=42
        )

        # ä½¿ç”¨ LinearSVC ä½œä¸ºåŸºç¡€æ¨¡å‹
        base_model = LinearSVC(
            C=1.0,
            class_weight='balanced',
            dual=False,  # å½“ n_samples > n_features æ—¶è®¾ä¸º False
            max_iter=5000,
            random_state=42
        )

        # ä½¿ç”¨ CalibratedClassifierCV æ”¯æŒæ¦‚ç‡è¾“å‡º
        model = ImbPipeline([
            ('scaler', StandardScaler()),
            ('smote', SMOTE(random_state=42)),
            ('classifier', CalibratedClassifierCV(base_model, method='sigmoid', cv=5))
        ])

        # å¯ç”¨å¤šçº¿ç¨‹è®­ç»ƒ
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        with parallel_backend('threading', n_jobs=-1):  # ä½¿ç”¨å¤šçº¿ç¨‹
            model.fit(X_train, y_train)

        # è¯„ä¼°æ¨¡å‹
        train_score = model.score(X_train, y_train)
        val_score = model.score(X_val, y_val)
        print(f"è®­ç»ƒé›†åˆ†æ•°ï¼š{train_score:.4f}, éªŒè¯é›†åˆ†æ•°ï¼š{val_score:.4f}")

        # ä¿å­˜æ¨¡å‹
        os.makedirs(save_dir, exist_ok=True)
        joblib.dump(model, f'{save_dir}/hog_lbp_svm_model.pkl')
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{save_dir}/hog_lbp_svm_model.pkl")

    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥ï¼š{str(e)}")
        raise

def predict(features):
    """é¢„æµ‹æƒ…ç»ªæ¦‚ç‡"""
    model = joblib.load('models/hog_lbp_svm_model.pkl')
    return model.predict_proba([features])[0]

def valid_model(model_path, valid_data_dir):
    """éªŒè¯æ¨¡å‹"""
    try:
        model = joblib.load(f'{model_path}/hog_lbp_svm_model.pkl')
        y_true, y_pred = [], []

        for emotion_idx, emotion in enumerate(EMOTIONS):
            emotion_dir = os.path.join(valid_data_dir, emotion)
            if not os.path.isdir(emotion_dir):
                continue

            for fname in os.listdir(emotion_dir):
                if fname.lower().endswith(('.png', '.jpg', '.jpeg')):
                    img_path = os.path.join(emotion_dir, fname)
                    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
                    if image is None:
                        logging.warning(f"æ— æ³•è¯»å–å›¾åƒï¼š{img_path}")
                        continue

                    try:
                        features = extract_hybrid_features(image)
                        pred = model.predict([features])[0]
                        y_true.append(emotion_idx)
                        y_pred.append(pred)
                    except Exception as e:
                        logging.error(f"å¤„ç†å›¾åƒå‡ºé”™ï¼š{img_path}", exc_info=True)

        # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
        from sklearn.metrics import classification_report
        print("\nåˆ†ç±»æŠ¥å‘Šï¼š")
        print(classification_report(
            y_true, y_pred,
            target_names=EMOTIONS,
            digits=4
        ))

    except Exception as e:
        logging.error("éªŒè¯è¿‡ç¨‹å‡ºé”™", exc_info=True)
        raise