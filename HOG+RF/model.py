#from sklearnex import patch_sklearn
#patch_sklearn()

EMOTIONS = ['angry', 'disgusted', 'fearful',
            'happy', 'sad', 'surprised', 'neutral']

import cv2
import os
import joblib
import numpy as np
import pandas as pd
from skimage.feature import hog
from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from joblib import Parallel, delayed
from albumentations import (
    Compose, HorizontalFlip, RandomBrightnessContrast,
    ShiftScaleRotate, ToFloat
)
from skimage.feature import local_binary_pattern
from sklearn.ensemble import RandomForestClassifier


# HOGå‚æ•°é…ç½®
HOG_PARAMS = {
    'orientations': 9,
    'pixels_per_cell': (8, 8),
    'cells_per_block': (2, 2),
    'block_norm': 'L2-Hys',
    'transform_sqrt': True  # ä¼½é©¬æ ¡æ­£
}

"""
16,8,3:è®­ç»ƒé›†åˆ†æ•°ï¼š0.5583, éªŒè¯é›†åˆ†æ•°ï¼š0.4136
16,8,2:è®­ç»ƒé›†åˆ†æ•°ï¼š0.5278, éªŒè¯é›†åˆ†æ•°ï¼š0.4081
16,6,3:è®­ç»ƒé›†åˆ†æ•°ï¼š0.6985, éªŒè¯é›†åˆ†æ•°ï¼š0.4147
12,6,3:è®­ç»ƒé›†åˆ†æ•°ï¼š0.6498, éªŒè¯é›†åˆ†æ•°ï¼š0.4235
12,4,4:è®­ç»ƒé›†åˆ†æ•°ï¼š0.9196, éªŒè¯é›†åˆ†æ•°ï¼š0.4198
9,8,2:è®­ç»ƒé›†åˆ†æ•°ï¼š0.4792, éªŒè¯é›†åˆ†æ•°ï¼š0.4081
9,8,2;9,16,1æ··åˆï¼šè®­ç»ƒé›†åˆ†æ•°ï¼š0.4899, éªŒè¯é›†åˆ†æ•°ï¼š0.4146(log_loss)
982:è®­ç»ƒé›†åˆ†æ•°ï¼š0.4764, éªŒè¯é›†åˆ†æ•°ï¼š0.3977(hinge)
"""







# ä¿®æ”¹æ•°æ®å¢å¼ºé…ç½®
AUGMENTATIONS = Compose([
    HorizontalFlip(p=0.3),
    RandomBrightnessContrast(
        brightness_limit=0.1,
        contrast_limit=0.1,
        p=0.3
    )
])



# ç¡®ä¿è®­ç»ƒå’Œæµ‹è¯•æ—¶ä½¿ç”¨ç›¸åŒçš„ç‰¹å¾æå–å‡½æ•°
def extract_features(data):
    """ç»Ÿä¸€ç‰¹å¾æå–å…¥å£"""
    # è§£æè¾“å…¥æ•°æ®
    if isinstance(data, (str, bytes)):
        if isinstance(data, bytes):
            data = data.decode('utf-8', errors='ignore')
        pixel_list = list(map(int, data.split()))
        image = np.array(pixel_list, dtype=np.uint8).reshape(48, 48)
        image = np.array(pixel_list, dtype=np.uint8).reshape(48, 48)
    elif isinstance(data, np.ndarray):
        image = data.reshape(48, 48) if data.size == 2304 else data
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹")

    # æå–å¤šå°ºåº¦ HOG ç‰¹å¾
    return extract_hog_features(image)



def extract_hog_features(data):
    """
    ä»åƒç´ æ•°æ®ä¸­æå–HOGç‰¹å¾
    æ­¤å‡½æ•°æ”¯æŒä¸¤ç§è¾“å…¥æ ¼å¼ï¼š
      - å­—ç¬¦ä¸²ï¼ˆæˆ–bytesï¼‰ï¼šç©ºæ ¼åˆ†éš”çš„åƒç´ å€¼å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ CSV æ–‡ä»¶ä¸­çš„å†…å®¹ã€‚
      - numpy.ndarrayï¼šç›´æ¥ä¼ å…¥å›¾åƒæ•°ç»„ï¼ˆ1Dæˆ–2Dï¼‰ã€‚
    """
    # å¦‚æœè¾“å…¥æ˜¯å­—ç¬¦ä¸²æˆ–bytesï¼ŒæŒ‰ç©ºæ ¼åˆ†å‰²è§£æä¸ºæ•´æ•°
    if isinstance(data, (str, bytes)):
        if isinstance(data, bytes):
            data = data.decode('utf-8', errors='ignore')
        pixel_list = list(map(int, data.split()))
        if len(pixel_list) != 48 * 48:
            raise ValueError(f"åƒç´ æ•°é‡é”™è¯¯ï¼š{len(pixel_list)}ï¼ˆåº”=2304ï¼‰")
        image = np.array(pixel_list, dtype=np.uint8).reshape(48, 48)
    # å¦‚æœè¾“å…¥æ˜¯ numpy æ•°ç»„ï¼Œç›´æ¥ä½¿ç”¨
    elif isinstance(data, np.ndarray):
        # å¦‚æœæ˜¯æ‰å¹³æ•°ç»„ï¼Œåˆ™å°è¯•é‡å¡‘ä¸º (48,48)
        if data.ndim == 1:
            if data.size != 48 * 48:
                raise ValueError(f"æ•°ç»„å¤§å°é”™è¯¯ï¼š{data.size} (åº”ä¸º2304)")
            image = data.reshape(48, 48)
        else:
            image = data
    else:
        raise ValueError("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹")

    try:
        # åº”ç”¨æ•°æ®å¢å¼º
        #augmented = AUGMENTATIONS(image=image)['image']
        #augmented = np.clip(augmented, 0, 255).astype(np.uint8)
        augmented = image
    except Exception as e:
        print(f"âš ï¸ æ•°æ®å¢å¼ºå¤±è´¥ï¼š{str(e)}")
        augmented = image

    # æå–HOGç‰¹å¾
    features = hog(
        augmented,
        orientations=HOG_PARAMS['orientations'],
        pixels_per_cell=HOG_PARAMS['pixels_per_cell'],
        cells_per_block=HOG_PARAMS['cells_per_block'],
        block_norm=HOG_PARAMS['block_norm']
    )
    return features

"""
    def extract_multi_scale_hog(image):
        #å¤šå°ºåº¦HOGç‰¹å¾èåˆ
        # ç¬¬ä¸€å°ºåº¦ï¼š8x8å•å…ƒ
        hog_small = hog(
            image,
            orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(2, 2),
            block_norm='L2-Hys'
        )

        # ç¬¬äºŒå°ºåº¦ï¼š16x16å•å…ƒ
        hog_large = hog(
            image,
            orientations=9,
            pixels_per_cell=(16, 16),
            cells_per_block=(1, 1),
            block_norm='L2-Hys'
        )

        return np.concatenate([hog_small, hog_large])

    features = extract_multi_scale_hog(image)
    return features
"""




def image_to_tensor(image):
    """å°†å›¾åƒè½¬æ¢ä¸º HOG ç‰¹å¾"""
    # è¾“å…¥åº”ä¸º 48x48 ç°åº¦å›¾
    if image.shape != (48, 48):
        image = cv2.resize(image, (48, 48))
    features = extract_hog_features(image)
    return features.reshape(1, -1)


def load_data(data_path):
    """åŠ è½½æŒ‡å®šæ•°æ®å­é›†ï¼ˆTraining + PublicTestï¼‰"""
    print("â³ åŠ è½½æ•°æ®å¹¶æå–ç‰¹å¾...")
    df = pd.read_csv(data_path)

    # ç­›é€‰å‡ºè®­ç»ƒé›†å’Œå…¬å¼€æµ‹è¯•é›†
    selected_data = df[df['Usage'].isin(['Training', 'PublicTest'])]

    # ç‰¹å¾æå–ï¼ˆä¿æŒä¸åŸå§‹ä»£ç ä¸€è‡´ï¼‰
    X = Parallel(n_jobs=-1, verbose=10)(
        delayed(extract_features)(pixels)
        for pixels in selected_data['pixels']
    )

    X = np.array(X)
    y = selected_data['emotion'].values
    print(f"\nâœ… ç‰¹å¾æå–å®Œæˆï¼Œå…±åŠ è½½ {len(X)} ä¸ªæ ·æœ¬ï¼ˆTraining+PublicTestï¼‰")
    return X, y


def train_model(data_path, save_dir):
    try:
        # åŠ è½½åˆå¹¶åçš„æ•°æ®é›†
        X, y = load_data(data_path)

        # é‡æ–°åˆ’åˆ†è®­ç»ƒé›†ä¸éªŒè¯é›†
        X_train, X_val, y_train, y_val = train_test_split(
            X, y,
            test_size=0.2,
            stratify=y,
            random_state=42
        )

        # ä¿æŒåŸæœ‰è®­ç»ƒæµç¨‹ä¸å˜
        model = ImbPipeline([
            ('scaler', StandardScaler()),
            ('smote', SMOTE(random_state=42)),
            ('classifier', RandomForestClassifier(
                n_estimators=200,
                max_depth=10,
                class_weight='balanced',
                n_jobs=-1,
                random_state=42
            ))
        ])

        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        model.fit(X_train, y_train)

        # === å…³é”®ä¿®æ­£ç‚¹ï¼šæ­£ç¡®å®šä¹‰è¯„ä¼°æŒ‡æ ‡ ===
        train_score = model.score(X_train, y_train)
        val_score = model.score(X_val, y_val)  # ç°åœ¨æ­£ç¡®å®šä¹‰

        # ç‹¬ç«‹å…¬å¼€æµ‹è¯•é›†è¯„ä¼°
        public_test = pd.read_csv(data_path).query("Usage == 'PublicTest'")
        X_public = np.array([extract_features(p) for p in public_test['pixels']])
        y_public = public_test['emotion'].values
        public_score = model.score(X_public, y_public)

        # æ‰“å°æ‰€æœ‰è¯„ä¼°ç»“æœ
        print(f"è®­ç»ƒé›†åˆ†æ•°ï¼š{train_score:.4f}")
        print(f"éªŒè¯é›†åˆ†æ•°ï¼ˆéšæœºåˆ’åˆ†ï¼‰ï¼š{val_score:.4f}")
        print(f"å…¬å¼€æµ‹è¯•é›†åˆ†æ•°ï¼ˆç‹¬ç«‹è¯„ä¼°ï¼‰ï¼š{public_score:.4f}")

        # ä¿å­˜æ¨¡å‹ï¼ˆä¿æŒä¸å˜ï¼‰
        os.makedirs(save_dir, exist_ok=True)
        joblib.dump(model, f'{save_dir}/hog_svm_model.pkl')

    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥ï¼š{str(e)}")
        raise



def predict(features):
    """é¢„æµ‹æƒ…ç»ªæ¦‚ç‡"""
    model = joblib.load('models/hog_svm_model.pkl')
    return model.predict_proba([features])[0]




def valid_model(model_path, valid_dir):
    """éªŒè¯æ¨¡å‹"""
    model = joblib.load(f'{model_path}/hog_svm_model.pkl')
    if not os.path.exists(valid_dir):
        print(f"âŒ éªŒè¯ç›®å½•ä¸å­˜åœ¨ï¼š{valid_dir}")
        return

    for fname in os.listdir(valid_dir):
        if fname.endswith('.jpg'):
            image_path = os.path.join(valid_dir, fname)
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
            if image is None:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒï¼š{image_path}")
                continue

            # æå–HOGç‰¹å¾å¹¶é¢„æµ‹
            features = image_to_tensor(image)
            result = model.predict_proba(features)
            pred_emotion = EMOTIONS[np.argmax(result)]
            print(f"{fname}: {pred_emotion}")